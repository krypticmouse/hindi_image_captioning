{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install git+https://github.com/huggingface/transformers.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-20T13:25:55.611504Z","iopub.execute_input":"2021-11-20T13:25:55.612142Z","iopub.status.idle":"2021-11-20T13:26:39.584523Z","shell.execute_reply.started":"2021-11-20T13:25:55.612056Z","shell.execute_reply":"2021-11-20T13:26:39.583415Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/rathiankit03/ImageCaptionHindi/master/Flickr8kHindiDataset/Flickr8k-Hindi.txt","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:26:39.589218Z","iopub.execute_input":"2021-11-20T13:26:39.589492Z","iopub.status.idle":"2021-11-20T13:26:40.959762Z","shell.execute_reply.started":"2021-11-20T13:26:39.589456Z","shell.execute_reply":"2021-11-20T13:26:40.958527Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:26:40.962857Z","iopub.execute_input":"2021-11-20T13:26:40.963572Z","iopub.status.idle":"2021-11-20T13:26:42.637117Z","shell.execute_reply.started":"2021-11-20T13:26:40.963522Z","shell.execute_reply":"2021-11-20T13:26:42.636107Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nbase_path = '../input/flickr8k/Images/'\nwith open('./Flickr8k-Hindi.txt') as f:\n    data = []\n    \n    for i in f.readlines():\n        sp = i.split(' ')\n        data.append([sp[0] + '.jpg', ' '.join(sp[1:])])\n        \nhindi = pd.DataFrame(data, columns = ['images', 'text'])\n#hindi['images'] = hindi['images']!='2258277193_58694969e2'\nhindi.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:26:42.640091Z","iopub.execute_input":"2021-11-20T13:26:42.640634Z","iopub.status.idle":"2021-11-20T13:26:42.808257Z","shell.execute_reply.started":"2021-11-20T13:26:42.640586Z","shell.execute_reply":"2021-11-20T13:26:42.807335Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"hindi = hindi[hindi['images']!='2258277193_586949ec62.jpg']\n#2258277193_586949ec62\n#df = df[df.line_race != 0]\nhindi","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:26:42.809801Z","iopub.execute_input":"2021-11-20T13:26:42.810131Z","iopub.status.idle":"2021-11-20T13:26:42.837133Z","shell.execute_reply.started":"2021-11-20T13:26:42.810086Z","shell.execute_reply":"2021-11-20T13:26:42.836112Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(hindi, test_size=0.2)\n# we reset the indices to start from zero\ntrain_df.reset_index(drop=True, inplace=True)\ntest_df.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:26:42.838802Z","iopub.execute_input":"2021-11-20T13:26:42.839969Z","iopub.status.idle":"2021-11-20T13:26:43.802555Z","shell.execute_reply.started":"2021-11-20T13:26:42.839907Z","shell.execute_reply":"2021-11-20T13:26:43.801601Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\nclass Image_Caption_Dataset(Dataset):\n    def __init__(self,root_dir,df, feature_extractor,tokenizer,max_target_length=512):\n        self.root_dir = root_dir\n        self.df = df\n        self.feature_extractor = feature_extractor\n        self.tokenizer = tokenizer\n        self.max_length=max_target_length\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self,idx):\n        #return image\n        image_path = self.df['images'][idx]\n        text = self.df['text'][idx]\n        #prepare image\n        image = Image.open(self.root_dir+'/'+image_path).convert(\"RGB\")\n        pixel_values = self.feature_extractor(image, return_tensors=\"pt\").pixel_values\n        #add captions by encoding the input\n        captions = self.tokenizer(text,\n                                 padding='max_length',\n                                 max_length=self.max_length).input_ids\n        captions = [caption if caption != self.tokenizer.pad_token_id else -100 for caption in captions]\n        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(captions)}\n        return encoding","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:26:43.804795Z","iopub.execute_input":"2021-11-20T13:26:43.805486Z","iopub.status.idle":"2021-11-20T13:26:43.817433Z","shell.execute_reply.started":"2021-11-20T13:26:43.805437Z","shell.execute_reply":"2021-11-20T13:26:43.816366Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import ViTFeatureExtractor,AutoTokenizer\n\nencoder_checkpoint = 'google/vit-base-patch16-224'\ndecoder_checkpoint = 'surajp/gpt2-hindi'\n\nfeature_extractor = ViTFeatureExtractor.from_pretrained(encoder_checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(decoder_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:26:43.818995Z","iopub.execute_input":"2021-11-20T13:26:43.819509Z","iopub.status.idle":"2021-11-20T13:27:00.877897Z","shell.execute_reply.started":"2021-11-20T13:26:43.819451Z","shell.execute_reply":"2021-11-20T13:27:00.876873Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"root_dir = \"../input/flickr8k/Images\"\n\n\ntrain_dataset = Image_Caption_Dataset(root_dir=root_dir,\n                           df=train_df,\n                           feature_extractor=feature_extractor,\n                                     tokenizer=tokenizer)\nval_dataset = Image_Caption_Dataset(root_dir=root_dir,\n                           df=test_df,\n                           feature_extractor=feature_extractor,\n                                     tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:27:00.879969Z","iopub.execute_input":"2021-11-20T13:27:00.880326Z","iopub.status.idle":"2021-11-20T13:27:00.888045Z","shell.execute_reply.started":"2021-11-20T13:27:00.880277Z","shell.execute_reply":"2021-11-20T13:27:00.886742Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:27:00.893354Z","iopub.execute_input":"2021-11-20T13:27:00.893785Z","iopub.status.idle":"2021-11-20T13:27:00.902505Z","shell.execute_reply.started":"2021-11-20T13:27:00.893739Z","shell.execute_reply":"2021-11-20T13:27:00.900795Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"encoding = train_dataset[0]\nfor k,v in encoding.items():\n  print(k, v.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:27:00.905109Z","iopub.execute_input":"2021-11-20T13:27:00.905529Z","iopub.status.idle":"2021-11-20T13:27:00.995862Z","shell.execute_reply.started":"2021-11-20T13:27:00.905485Z","shell.execute_reply":"2021-11-20T13:27:00.994844Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"labels = encoding['labels']\nlabels[labels == -100] = tokenizer.pad_token_id\nlabel_str = tokenizer.decode(labels, skip_special_tokens=True)\nprint(label_str)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:27:00.997278Z","iopub.execute_input":"2021-11-20T13:27:00.997819Z","iopub.status.idle":"2021-11-20T13:27:01.024576Z","shell.execute_reply.started":"2021-11-20T13:27:00.997773Z","shell.execute_reply":"2021-11-20T13:27:01.023366Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\neval_dataloader = DataLoader(val_dataset, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:27:01.026519Z","iopub.execute_input":"2021-11-20T13:27:01.027026Z","iopub.status.idle":"2021-11-20T13:27:01.033523Z","shell.execute_reply.started":"2021-11-20T13:27:01.026980Z","shell.execute_reply":"2021-11-20T13:27:01.032280Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from transformers import VisionEncoderDecoderModel\n# initialize a vit-bert from a pretrained ViT and a pretrained BERT model. Note that the cross-attention layers will be randomly initialized\nmodel = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(encoder_checkpoint, decoder_checkpoint)\n#model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:27:01.036057Z","iopub.execute_input":"2021-11-20T13:27:01.036602Z","iopub.status.idle":"2021-11-20T13:28:13.275431Z","shell.execute_reply.started":"2021-11-20T13:27:01.036535Z","shell.execute_reply":"2021-11-20T13:28:13.274352Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n# set special tokens used for creating the decoder_input_ids from the labels\nmodel.config.decoder_start_token_id = tokenizer.bos_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n# make sure vocab size is set correctly\nmodel.config.vocab_size = model.config.decoder.vocab_size\n\n# set beam search parameters\nmodel.config.eos_token_id = tokenizer.sep_token_id\nmodel.config.max_length = 512\nmodel.config.early_stopping = True\nmodel.config.no_repeat_ngram_size = 3\nmodel.config.length_penalty = 2.0\nmodel.config.num_beams = 4","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:28:13.277117Z","iopub.execute_input":"2021-11-20T13:28:13.280655Z","iopub.status.idle":"2021-11-20T13:28:13.287990Z","shell.execute_reply.started":"2021-11-20T13:28:13.280621Z","shell.execute_reply":"2021-11-20T13:28:13.286725Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.decoder.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:28:13.289597Z","iopub.execute_input":"2021-11-20T13:28:13.290100Z","iopub.status.idle":"2021-11-20T13:28:13.988765Z","shell.execute_reply.started":"2021-11-20T13:28:13.290052Z","shell.execute_reply":"2021-11-20T13:28:13.987809Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"for param in model.encoder.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:28:13.990594Z","iopub.execute_input":"2021-11-20T13:28:13.990939Z","iopub.status.idle":"2021-11-20T13:28:13.996636Z","shell.execute_reply.started":"2021-11-20T13:28:13.990887Z","shell.execute_reply":"2021-11-20T13:28:13.995737Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(total_params)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:28:13.998687Z","iopub.execute_input":"2021-11-20T13:28:13.999560Z","iopub.status.idle":"2021-11-20T13:28:14.012223Z","shell.execute_reply.started":"2021-11-20T13:28:13.999518Z","shell.execute_reply":"2021-11-20T13:28:14.011222Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(train_total_params)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:28:14.014236Z","iopub.execute_input":"2021-11-20T13:28:14.015178Z","iopub.status.idle":"2021-11-20T13:28:14.025947Z","shell.execute_reply.started":"2021-11-20T13:28:14.015124Z","shell.execute_reply":"2021-11-20T13:28:14.024743Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:28:19.266013Z","iopub.execute_input":"2021-11-20T13:28:19.266348Z","iopub.status.idle":"2021-11-20T13:28:34.051768Z","shell.execute_reply.started":"2021-11-20T13:28:19.266316Z","shell.execute_reply":"2021-11-20T13:28:34.050742Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_scheduler\nfrom tqdm.notebook import tqdm\nimport torch\n\n\nn_epochs = 10\noptimizer = AdamW(model.parameters(), lr=5e-5)\nnb_train_steps = int(\n        len(train_dataloader) / 8 * n_epochs\n    )\nscheduler = get_scheduler(\n        'linear',\n        optimizer,\n        num_warmup_steps=0,\n        num_training_steps=nb_train_steps,\n    )\n    \nscaler = torch.cuda.amp.GradScaler()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:32:16.735972Z","iopub.execute_input":"2021-11-20T13:32:16.736268Z","iopub.status.idle":"2021-11-20T13:32:16.802015Z","shell.execute_reply.started":"2021-11-20T13:32:16.736233Z","shell.execute_reply":"2021-11-20T13:32:16.800882Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0'\nmodel.to(device)\nprint('.')","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:39:24.146083Z","iopub.execute_input":"2021-11-20T13:39:24.146427Z","iopub.status.idle":"2021-11-20T13:39:24.166206Z","shell.execute_reply.started":"2021-11-20T13:39:24.146397Z","shell.execute_reply":"2021-11-20T13:39:24.164189Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def train_step(model,train_dl,optimizer,scheduler,epoch):\n    model.train()\n    train_loss = 0.0\n    for batch in tqdm(train_dl):\n        for k, v in batch.items():\n            batch[k] = v.to(device)\n            \n        with torch.cuda.amp.autocast():\n            outputs = model(**batch)\n            loss = outputs.loss\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        train_loss += loss.item()\n        return train_loss\n    \n    \ndef valid_step(model,valid_dl,optimizer,scheduler,epoch):\n    model.eval()\n    valid_loss = 0.0\n    for batch in tqdm(valid_dl):\n        for k, v in batch.items():\n            batch[k] = v.to(device)\n            \n       \n        outputs = model(**batch)\n            \n        loss = outputs.loss\n        \n        valid_loss += loss.item()\n        return valid_loss","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:41:22.727306Z","iopub.execute_input":"2021-11-20T13:41:22.727597Z","iopub.status.idle":"2021-11-20T13:41:22.737986Z","shell.execute_reply.started":"2021-11-20T13:41:22.727565Z","shell.execute_reply":"2021-11-20T13:41:22.736802Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"for epoch in range(n_epochs):\n    tr_loss = train_step(model,train_dataloader,optimizer,scheduler,epoch)\n    vl_loss\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-20T13:41:23.346393Z","iopub.execute_input":"2021-11-20T13:41:23.346973Z","iopub.status.idle":"2021-11-20T13:41:24.187741Z","shell.execute_reply.started":"2021-11-20T13:41:23.346941Z","shell.execute_reply":"2021-11-20T13:41:24.186580Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"\n\nfor epoch in range(n_epochs):  # loop over the dataset multiple times\n   # train\n   model.train()\n   train_loss = 0.0\n   for batch in tqdm(train_dataloader):\n      # get the inputs\n      for k,v in batch.items():\n        batch[k] = v.to(device)\n\n      with torch.cuda.amp.autocast():\n        outputs = model(**batch)\n      #outputs = model(**batch)\n      \n      loss = outputs.loss\n      #loss.backward()\n      \n      train_loss += loss.item()\n\n   print(f\"Loss after epoch {epoch}:\", train_loss/len(train_dataloader))\n    \n   # evaluate\n   model.eval()\n   with torch.no_grad():\n     for batch in tqdm(eval_dataloader):\n       # run batch generation\n       outputs = model.generate(batch[\"pixel_values\"].to(device))\n       # compute metrics\n       loss = outputs.loss\n\n   print(\"Validation LOSS:\", valid_loss / len(eval_dataloader))\n\nmodel.save_pretrained(checkpoints_dir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    evaluation_strategy=\"steps\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    overwrite_output_dir=True,\n    fp16=True,\n    run_name=\"first_run\",\n    load_best_model_at_end=True,\n    output_dir=\"./image_captioning_checkpoint\",\n    logging_steps=2000,\n    save_steps=2000,\n    eval_steps=2000,\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T12:12:36.103093Z","iopub.execute_input":"2021-11-20T12:12:36.103362Z","iopub.status.idle":"2021-11-20T12:12:36.11543Z","shell.execute_reply.started":"2021-11-20T12:12:36.103333Z","shell.execute_reply":"2021-11-20T12:12:36.114714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env WANDB_PROJECT=HF_COMMUNITY_EVENT\n%env WANDB_LOG_MODEL=true","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:59:31.626564Z","iopub.execute_input":"2021-11-20T11:59:31.626831Z","iopub.status.idle":"2021-11-20T11:59:31.633945Z","shell.execute_reply.started":"2021-11-20T11:59:31.626801Z","shell.execute_reply":"2021-11-20T11:59:31.633064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import default_data_collator\n\n# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    tokenizer=feature_extractor,\n    args=training_args,\n    #compute_metrics=compute_metrics,\n    #it should be set to true only when we login inside\n    push_to_hub=True\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=default_data_collator,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-11-20T12:12:41.304436Z","iopub.execute_input":"2021-11-20T12:12:41.304688Z","iopub.status.idle":"2021-11-20T12:48:48.646991Z","shell.execute_reply.started":"2021-11-20T12:12:41.304653Z","shell.execute_reply":"2021-11-20T12:48:48.645708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = '1'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}